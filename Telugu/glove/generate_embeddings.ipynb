{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d70d829f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy.linalg as lin\n",
    "import warnings \n",
    "import pickle\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a6c22b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from indic_transliteration import sanscript\n",
    "from indic_transliteration.sanscript import transliterate\n",
    "\n",
    "def t2h(text):\n",
    "    return transliterate(text,sanscript.TELUGU,sanscript.DEVANAGARI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1742b701",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords=['కూడా', 'ఉన్నారు', 'ఎవరైనా', 'ఎప్పుడు', 'ఎక్కడైనా', 'అందుబాటులో', 'ఒక ప్రక్కన', 'సంబంధం', 'మాత్రమే', 'అడగండి', 'గా', 'మధ్య', 'ప్రకారం', 'అనుమతించు', 'మెచ్చుకో', 'వద్ద', 'తగిన', 'అడ్డంగా', 'అడగడం', 'ఇప్పటికే', 'కనిపిస్తాయి', 'కాదు', 'మరియు', 'మరొక', 'అనుగుణంగా', 'అయితే', 'చేయగలిగింది', 'దాదాపు', 'గురించి', 'పై', 'వెంట', 'వేరుగా', 'చుట్టూ', 'దూరంగా', 'ఏ', 'నిజంగా', 'అనుమతిస్తుంది', 'అందరూ', 'ఎవరో ఒకరు', 'వ్యతిరేకంగా', 'ఏదైనా', 'తర్వాత', 'మళ్ళీ', 'ఏమైనప్పటికి', 'ఒక']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a275004c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vowels=set(\"అ ఆ ఇ ఈ ఉ ఊ ఋ ౠ ఌ ౡ ఎ ఏ ఐ ఒ ఓ ఔ అం అః\".split())\n",
    "\n",
    "conso=\"క\tఖ\tగ\tఘ\tఙ\tచ\tఛ\tజ\tఝ\tఞ\tట\tఠ\tడ\tఢ\tణ\tత\tథ\tద\tధ\tన\tప\tఫ\tబ\tభ\tమ\tయ\tర\tల\tవ\tశ\tష\tస\tహ\tళ\tక్ష\tఱ\"\n",
    "\n",
    "matra = \"ఀ\tఁ\tం\tః\tఄ\tఽ\tా\tి\tీ\tు\tూ\tృ\tౄ\tె\tే\tై\tొ\tో\tౌ\t్\tౕ\tౖ\tౢ\tౣ\"\n",
    "\n",
    "halantha='్'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d15f7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "consonants=set(conso.split(\"\\t\"))\n",
    "matra = set(matra.split(\"\\t\"))\n",
    "\n",
    "vowels = list(vowels)\n",
    "consonants=list(consonants)\n",
    "matra=list(matra)\n",
    "\n",
    "alphabets = vowels+consonants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e50d76e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "delimiters=[\"।\",\"?\",\"!\",\".\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3df1ed97",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove=open('glove/te-d100-glove.txt','rb')\n",
    "txt=glove.read().decode(errors='replace')\n",
    "glove={}\n",
    "for line in txt.split(\"\\n\"):\n",
    "    line=line.strip()\n",
    "    line=line.split()\n",
    "    try:\n",
    "        glove[line[0]]=np.array(list(map(float,line[1:])))\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20ce371e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(text):\n",
    "    string=''\n",
    "    for i in text:\n",
    "        if i in alphabets+matra+delimiters:\n",
    "            string=string+i\n",
    "        else:\n",
    "            string=string+\" \"\n",
    "    return \" \".join(string.split())\n",
    "def sent_tokenize(text):\n",
    "    text=remove_special_characters(text)\n",
    "    regexPattern = '.'.join(map(re.escape, delimiters))\n",
    "    sentences=re.split(regexPattern,text)\n",
    "    return [sent.strip() for sent in sentences if len(sent.strip())>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcf1a2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_embedding(word):\n",
    "    try:\n",
    "        return glove[t2h(word)]\n",
    "    except:\n",
    "        return np.array([0.0]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fb025a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_embedding(sentence):\n",
    "    sentence=remove_special_characters(sentence)\n",
    "    words=sentence.split()\n",
    "    words=[word  for word in words if word not in stopwords]\n",
    "    if len(words)>0:\n",
    "        sentence_embedding=[word_embedding(word) for word in words]\n",
    "        return np.array(list(map(lambda x: sum(x)/len(x), zip(*sentence_embedding))))\n",
    "    return np.array([0.0]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "950a6d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('../telugu.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e51c98a",
   "metadata": {},
   "source": [
    "# Sentence By Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d0cb8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "verse_embeddings_sentence=[]\n",
    "verse_embeddings_max=[]\n",
    "verse_embeddings_mean=[]\n",
    "for i in range(len(data)):\n",
    "    text=data.loc[i]['Commentary']\n",
    "    sentences=sent_tokenize(text)\n",
    "    embeddings=[sentence_embedding(sentence) for sentence in sentences]\n",
    "    #sentence\n",
    "    verse_embeddings_sentence.append(embeddings)\n",
    "    #Max Pooling\n",
    "    norms=[lin.norm(i) for i in embeddings]\n",
    "    index=norms.index(max(norms))\n",
    "    verse_embeddings_max.append(embeddings[index])\n",
    "    #Mean Pooling\n",
    "    embeddings=np.array(list(map(lambda x: sum(x)/len(x), zip(*embeddings))))\n",
    "    verse_embeddings_mean.append(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9481ac",
   "metadata": {},
   "source": [
    "# Whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b93231c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "verse_embeddings_whole=[]\n",
    "for i in range(len(data)):\n",
    "    text=data.loc[i]['Commentary']\n",
    "    embeddings=sentence_embedding(text)\n",
    "    verse_embeddings_whole.append(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aec88ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file=open('sentence.pkl','wb')\n",
    "pickle.dump(verse_embeddings_sentence,file)\n",
    "file.close()\n",
    "file=open('max.pkl','wb')\n",
    "pickle.dump(verse_embeddings_max,file)\n",
    "file.close()\n",
    "file=open('mean.pkl','wb')\n",
    "pickle.dump(verse_embeddings_mean,file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fc37323",
   "metadata": {},
   "outputs": [],
   "source": [
    "file=open('whole.pkl','wb')\n",
    "pickle.dump(verse_embeddings_whole,file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f256bc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file=open('glove.pkl','wb')\n",
    "pickle.dump(glove,file)\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
